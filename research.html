---
layout: layout
title: Antonio Mallia's Blog
---
<div class="container">
<h3>Publications</h3>
  <div class="panel panel-default">
    <div class="panel-body">
    <h5>
            <span class="paper-authors">Luke Gallagher, <u>Antonio Mallia</u>, J. Shane Culpepper, Torsten Suel, B. Barla Cambazoglu.</span>
            <span class="paper-title">Feature Extraction for Large-Scale Text Collections.</span>
            <span class="paper-publisher">In Proceedings of the 29th ACM International Conference on Information and Knowledge Management (CIKM). 2020</span>
            <p> <small><u>Abstract</u>:
Feature engineering is a fundamental but poorly documented component in learning-to-rank (LTR) search engines. Such features are commonly used to construct learning models for web and product search engines, recommender systems and question-answering tasks. In each of these domains, there is a growing interest in the creation of open-access test collections that promote reproducible research. However, there are still few open source software packages capable of extracting high-quality machine learning features from large text collections. Instead, most feature-based LTR research relies on ``canned'' test collections, which often do not expose critical details about the underlying collection or implementation details of the features extracted. Both of these are crucial to collection creation and deployment of a search engine into production. So in this regard, the experiments are rarely reproducible with new features or collections, or helpful for companies wishing to deploy LTR systems. In this paper, we introduce Fxt, an open-source framework to perform efficient and scalable feature extraction. Fxt can easily be integrated into complex, high-performance software applications to help solve a wide variety of textual machine learning problems. To demonstrate the software's utility, we build and document a reproducible feature extraction pipeline and show how to recreate several common LTR experiments using the ClueWeb09B collection. Researchers and practitioners can benefit from Fxt to extend their machine learning pipelines for various text-based retrieval tasks, and learn how some static document features and query-specific features are implemented.
<!--             <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/CIKM20.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a> -->
<!--             <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/CIKM20.bib"><i class="fa fa-quote-right"></i> Cite</a> -->
    </h5>
    <h5>
            <span class="paper-authors"><u>Antonio Mallia</u>, Michal Siedlaczek, Mengyang Sun, Torsten Suel.</span>
            <span class="paper-title">A Comparison of Top-k Threshold Estimation Techniques for Disjunctive Query Processing.</span>
            <span class="paper-publisher">In Proceedings of the 29th ACM International Conference on Information and Knowledge Management (CIKM). 2020</span>
            <p> <small><u>Abstract</u>:
In the top-k threshold estimation problem, given a query q, the goal is to estimate the score of the result at rank k. A good estimate of this score can result in significant performance improvements for several query processing scenarios, including selective search, index tiering, and widely used disjunctive query processing algorithms such as MaxScore, WAND, and BMW. Several approaches have been proposed, including parametric approaches, methods using random sampling, and a recent approach based on machine learning. However, previous work fails to perform any experimental comparison between these approaches. In this paper, we address this issue by reimplementing four major approaches and comparing them in terms of estimation error, running time, likelihood of an overestimate, and end-to-end performance when applied to common classes of disjunctive top-k query processing algorithms.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/CIKM20.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/CIKM20.bib"><i class="fa fa-quote-right"></i> Cite</a>
    </h5>
    <h5>
            <span class="paper-authors">Jimmy Lin, Joel Mackenzie, Chris Kamphuis, Craig Macdonald, <u>Antonio Mallia</u>, Michal Siedlaczek, Andrew Trotman, Arjen de Vries.</span>
            <span class="paper-title">Supporting Interoperability Between Open-Source Search Engines with the Common Index File Format.</span>
            <span class="paper-publisher">In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR). 2020</span>
            <p> <small><u>Abstract</u>:
        There exists a natural tension between encouraging a diverse ecosystem of open-source search engines and supporting fair, replicable comparisons across those systems. To balance these two goals, we examine two approaches to providing interoperability between the inverted indexes of several systems. The first takes advantage of internal abstractions around index structures and building wrappers that allow one system to directly read the indexes of another. The second involves sharing indexes across systems via a data exchange specification that we have developed, called the Common Index File Format (CIFF). We demonstrate the first approach with the Java systems Anserini and Terrier, and the second approach with Anserini, JASSv2, OldDog, PISA, and Terrier. Together, these systems provide a wide range of implementations and features, with different research goals. Overall, we recommend CIFF as a low-effort approach to support independent innovation while enabling the types of fair evaluations that are critical for driving the field forward.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/SIGIR20.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/SIGIR20.bib"><i class="fa fa-quote-right"></i> Cite</a>
    </h5>
    <h5>
            <span class="paper-authors"><u>Antonio Mallia</u>, Michal Siedlaczek, Torsten Suel and Mohamed Zahran.</span>
            <span class="paper-title">GPU-Accelerated Decoding of Integer Lists.</span>
            <span class="paper-publisher">In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM). 2019</span>
            <p> <small><u>Abstract</u>:
	    An inverted index is the basic data structure used in most current large-scale information retrieval systems. It can be modeled as a collection of sorted sequences of integers. Many compression techniques for inverted indexes have been studied in the past, with some of them reaching tremendous decompression speeds through the use of SIMD instructions available on modern CPUs. While there has been some work on query processing algorithms for Graphics Processing Units (GPUs), little of it has focused on how to efficiently access compressed index structures, and we see some potential for significant improvements in decompression speed.
	    In this paper, we describe and implement two encoding schemes for index decompression on GPU architectures. Their format and decoding algorithm is adapted from existing CPU-based compression methods to exploit the execution model and memory hierarchy offered by GPUs. We show that our solutions, GPU-BP and GPU-VByte, achieve significant speedups over their already carefully optimized CPU counterparts.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/CIKM19.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/CIKM19.bib"><i class="fa fa-quote-right"></i> Cite</a>
    </h5>
	<h5>
            <span class="paper-authors"><u>Antonio Mallia</u>.</span>
            <span class="paper-title">Efficient top-k document retrieval.</span>
            <span class="paper-publisher">In Proceedings of the 9th PhD Symposium on Future Directions in Information Access (FDIA). 2019</span>
            <p> <small><u>Abstract</u>:
	    Over the past few decades, the IR community has been making a continuous effort to improve the efficiency of search in large collections of documents. Query processing is still one of the main bottlenecks in large-scale search systems.  The top-k document retrieval problem, which can be defined as reporting the k most relevant documents from a collection for a given query, can be extremely expensive, as it involves scoring large amounts of documents.
	    In this work, we investigate the top-k document retrieval problem from several angles with the aim of improving the efficiency of this task in large-scale search systems.  Finally, we briefly describe our initial findings and conclude by proposing future directions to follow. </small></p>
        <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/FDIA19.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
        <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/FDIA19.bib"><i class="fa fa-quote-right"></i> Cite</a>
        </h5>
        <h5>
            <span class="paper-authors"><u>Antonio Mallia</u>, Michal Siedlaczek, Joel Mackenzie and Torsten Suel.</span>
            <span class="paper-title">PISA: Performant Indexes and Search for Academia.</span>
            <span class="paper-publisher">In Proceedings of the Open-Source IR Replicability Challenge (OSIRRC)  co-located with SIGIR. 2019</span>
            <p> <small><u>Abstract</u>:
            Performant Indexes and Search for Academia (PISA) is an experimental search engine that focuses on efficient implementations of  state-of-the-art representations and algorithms for text retrieval.
            In this work, we outline our effort in creating a replicable search run from PISA for the 2019 Open Source Information Retrieval Replicability Challenge, which encourages the information retrieval community to produce replicable systems through the use of a containerized, Docker-based infrastructure. We also discuss the origins, current functionality, and future direction and challenges for the PISA system.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/OSIRRC19.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/OSIRRC19.bib"><i class="fa fa-quote-right"></i> Cite</a>
        </h5>
        <h5>
            <span class="paper-authors"><u>Antonio Mallia</u>, Michal Siedlaczek and Torsten Suel.</span>
            <span class="paper-title">An Experimental Study of Index Compression and DAAT Query Processing Methods.</span>
            <span class="paper-publisher">In Proceedings of the 41st European Conference on Information Retrieval (ECIR). 2019</span>
            <p> <small><u>Abstract</u>:
            In the last two decades, the IR community has seen numerous advances in top-k query processing and inverted index compression techniques. While newly proposed techniques are typically proposed against a few baselines, these evaluations are often very limited, and we feel that there is no clear overall picture on the best choices of algorithms and compression methods.
            In this paper, we attempt to address this issue by evaluating a number of state-of-the-art index compression methods and safe disjunctive DAAT query processing algorithms. Our goal is to understand how much index compression performance impacts overall query processing speeds, how the choice of query processing algorithm depends on the compression method used, and how performance is impacted by document reordering techniques and the number of results returned, keeping in mind that current search engines typically use sets of hundreds or thousands of candidates for further reranking.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/ECIR19c.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/ECIR19c.bib"><i class="fa fa-quote-right"></i> Cite</a>
        </h5>
         <h5>
            <span class="paper-authors">Joel Mackenzie, <u>Antonio Mallia</u>, Matthias Petri, J. Shane Culpepper and Torsten Suel.</span>
            <span class="paper-title">Compressing Inverted Indexes with Recursive Graph Bisection: A Reproducibility Study.</span>
            <span class="paper-publisher">In Proceedings of the 41st European Conference on Information Retrieval (ECIR). 2019</span>
            <p> <small><u>Abstract</u>:
            Document reordering is an important but often overlooked preprocessing stage in index construction. Reordering document identifiers in graphs and inverted indexes has been shown to reduce storage costs and improve processing efficiency in the resulting indexes.
            However, surprisingly few document reordering algorithms are publicly available despite their importance.
            A new reordering algorithm derived from recursive graph bisection was recently proposed by Dhulipala et al., and shown to be highly
            effective and efficient when compared against other state-of-the-art reordering strategies.
            In this work, we present a reproducibility study of this new algorithm.
            We describe both the implementation challenges faced, as well as the performance characteristics of our clean-room reimplementation.
            We show that we are able to successfully reproduce the core results of the original paper, and show that the algorithm generalizes to
            other collections and indexing frameworks.
            Furthermore, we make our implementation publicly available to help promote further research in this space.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/ECIR19b.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/ECIR19b.bib"><i class="fa fa-quote-right"></i> Cite</a>
        </h5>
        <h5>
            <span class="paper-authors"><u>Antonio Mallia</u>, Elia Porciani.</span>
            <span class="paper-title">Faster BlockMax WAND with Longer Skipping.</span>
            <span class="paper-publisher">In Proceedings of the 41st European Conference on Information Retrieval (ECIR). 2019</span>
            <p> <small><u>Abstract</u>: One of the major problems for modern search engines is to keep up with the tremendous growth in the size of the web and the number of queries submitted by users. The amount of data being generated today can only be processed and managed with specialized technologies.
            BlockMaxWAND and the more recent Variable BlockMaxWAND represent the most advanced query processing algorithms that make use of dynamic pruning techniques, which allow them to retrieve the top k most relevant documents for a given query without any effectiveness degradation of its ranking.
            In this paper, we describe a new technique for the BlockMaxWAND family of query processing algorithm, which improves block skipping in order to increase its efficiency.
            We show that our optimization is able to improve query processing speed on short queries by up to 37% with negligible additional space overhead.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/ECIR19a.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/ECIR19a.bib"><i class="fa fa-quote-right"></i> Cite</a>
        </h5>
        <h5>
            <span class="paper-authors">Melanie Tosik, <u>Antonio Mallia</u>, Kedar Gangopadhyay.</span>
            <span class="paper-title">Debunking Fake News One Feature at a Time.</span>
            <span class="paper-publisher">CoRR abs/1808.02831. 2018</span>
            <p> <small><u>Abstract</u>: Identifying the stance of a news article body with respect to a certain headline is the first step to automated fake news detection. In this paper, we introduce a 2-stage ensemble model to solve the stance detection task. By using only hand-crafted features as input to a gradient boosting classifier, we are able to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake News Challenge (Stage 1) dataset. We identify the most useful features for detecting fake news and discuss how sampling techniques can be used to improve recall accuracy on a highly imbalanced dataset.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/pdf/1808.02831.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/FN18.bib"><i class="fa fa-quote-right"></i> Cite</a>

        </h5>
        <h5>
            <span class="paper-authors"><u>Antonio Mallia</u>, Giuseppe Ottaviano, Elia Porciani, Nicola Tonellotto, and Rossano Venturini.</span>
            <span class="paper-title">Faster BlockMax WAND with Variable-sized Blocks.</span>
            <span class="paper-publisher">In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR). 2017</span>
            <p> <small><u>Abstract</u>: Query processing is one of the main bottlenecks in large-scale search engines. Retrieving the top k most relevant documents for a given query can be extremely expensive, as it involves scoring large amounts of documents. Several dynamic pruning techniques have been introduced in the literature to tackle this problem, such as BlockMaxWAND, which splits the inverted index into constant- sized blocks and stores the maximum document-term scores per block; this information can be used during query execution to safely skip low-score documents, producing many-fold speedups over exhaustive methods. We introduce a refinement for BlockMaxWAND that uses variable- sized blocks, rather than constant-sized. We set up the problem of deciding the block partitioning as an optimization problem which maximizes how accurately the block upper bounds represent the underlying scores, and describe an efficient algorithm to find an approximate solution, with provable approximation guarantees. rough an extensive experimental analysis we show that our method significantly outperforms the state of the art roughly by a factor 2Ã—. We also introduce a compressed data structure to represent the additional block information, providing a compression ratio of roughly 50%, while incurring only a small speed degradation, no more than 10% with respect to its uncompressed counterpart.</small></p>
            <a class="btn btn-outline-primary btn-sm" href="{{ site.url }}/uploads/SIGIR17a.pdf" target="_blank" rel="noopener"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> PDF</a>
            <a class="btn btn-outline-primary btn-sm js-cite-modal" data-filename="/uploads/SIGIR17a.bib"><i class="fa fa-quote-right"></i> Cite</a>
        </h5>
	</div>
  </div>
<h3>Other activities</h3>
  <div class="panel panel-default">
    <div class="panel-body">
        <ul>
            <li>PC member for <a href="https://ecir2020.org/" target="_blank">ECIR 2020</a></li>
	        <li>External reviewer for <a href="https://www.kdd.org/kdd2020/" target="_blank">KDD 2020</a></li>
            <li>Reviewer for <a href="https://tweb.acm.org/" target="_blank">ACM Transactions on the Web (TWEB)</a></li>
            <li>External reviewer for <a href="http://www.kdd.org/kdd2019/" target="_blank">KDD 2019</a></li>
            <li>External reviewer for <a href="http://www.kdd.org/kdd2018/" target="_blank">KDD 2018</a></li>
        </ul>

    </div>
  </div>
</div>

<div id=modal class="modal fade" role=dialog>
   <div class=modal-dialog>
      <div class=modal-content>
         <div class=modal-header>
            <h3 class="modal-title">Export Citation</h3>
            <button type=button class=close data-dismiss=modal aria-label=Close>
            <span aria-hidden=true>&#215;</span></button>
         </div>
         <div class=modal-body>
            <pre><code class="tex hljs"></code></pre>
         </div>
         <div class=modal-footer>
            <a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fa fa-copy"></i> Copy</a>
            <a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fa fa-download"></i> Download</a>
            <div id=modal-error></div>
         </div>
      </div>
   </div>
</div>
